{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"baseline.ipynb","provenance":[],"collapsed_sections":["CHKQHkX27No-","gYpPMexIzim_"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"JZz9BGvqBqfQ"},"source":["https://github.com/kuangliu/pytorch-cifar"]},{"cell_type":"code","metadata":{"id":"za2IZSnTpel8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1604890705863,"user_tz":-540,"elapsed":31937,"user":{"displayName":"THWALCHUMYAET[학생](대학원 컴퓨터공학과) ‍","photoUrl":"","userId":"16713289985267776511"}},"outputId":"20653f66-2c46-4c6d-cac4-452b7c0e92bc"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"y50rVvKprBM6"},"source":["import os\n","import numpy as np\n","from datetime import datetime"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"neHZ36b1qL8S","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1604890707022,"user_tz":-540,"elapsed":33094,"user":{"displayName":"THWALCHUMYAET[학생](대학원 컴퓨터공학과) ‍","photoUrl":"","userId":"16713289985267776511"}},"outputId":"aa0e493b-9a7e-44ca-acec-519f604128f6"},"source":["# Root folder. Change this according to your folder structure.\n","ROOT_DIR = '/deeplearning/'\n","\n","zipped_data = os.path.join(ROOT_DIR, 'processed_data.zip')\n","\n","data_dir = '/content/data'\n","os.makedirs(data_dir, exist_ok=True)\n","!cp '{zipped_data}' '{data_dir}'"],"execution_count":null,"outputs":[{"output_type":"stream","text":["cp: cannot stat '/content/gdrive/My Drive/Class/2020-2nd-Semester/Deep Learning (CSE7512-00) (Sung Ho Bae)/project/processed_data.zip': No such file or directory\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"WQDglmbSrV0X","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1604890707023,"user_tz":-540,"elapsed":33094,"user":{"displayName":"THWALCHUMYAET[학생](대학원 컴퓨터공학과) ‍","photoUrl":"","userId":"16713289985267776511"}},"outputId":"53d0f10a-068f-4960-b57e-174ef96d000c"},"source":["!unzip -qq '{data_dir}/processed_data.zip' -d '{data_dir}'"],"execution_count":null,"outputs":[{"output_type":"stream","text":["unzip:  cannot find or open /content/data/processed_data.zip, /content/data/processed_data.zip.zip or /content/data/processed_data.zip.ZIP.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"lKDgbHaluzBB"},"source":["train_dir = os.path.join(data_dir, 'train')\n","valid_dir = os.path.join(data_dir, 'validation')\n","test_dir = os.path.join(data_dir, 'test')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4pETfpCOs7lr"},"source":["# Define Model"]},{"cell_type":"markdown","metadata":{"id":"GwGFABAkSE7k"},"source":["## LeNet_STL10"]},{"cell_type":"code","metadata":{"id":"NEVO8QzfsB33"},"source":["import torch\n","import torch.nn as nn\n","\n","class LeNet_STL10(nn.Module):\n","    def __init__(self):\n","        super(LeNet_STL10, self).__init__()\n","        self.num_classes = 10\n","\n","        self.relu = nn.ReLU(inplace=True)\n","        self.conv1 = nn.Conv2d(3, 6, kernel_size=5, stride=1)\n","        self.pool1 = nn.MaxPool2d((2, 2), stride=2)\n","        self.conv2 = nn.Conv2d(6, 16, kernel_size=5, stride=1)\n","        self.pool2 = nn.MaxPool2d((2, 2), stride=2)\n","        self.fc1 = nn.Linear(16*21*21, 120)\n","        self.fc2 = nn.Linear(120, 84)\n","        self.fc3 = nn.Linear(84, self.num_classes)\n","\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d):\n","                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n","\n","    def forward(self, x):\n","        x = self.relu(self.conv1(x))\n","        x = self.pool1(x)\n","\n","        x = self.relu(self.conv2(x))\n","        x = self.pool2(x)\n","        x = torch.flatten(x, 1)\n","\n","        x = self.relu(self.fc1(x))\n","        x = self.relu(self.fc2(x))\n","        x = self.fc3(x)\n","\n","        return x"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lOkYgjLxSpOD"},"source":["## DenseNet"]},{"cell_type":"code","metadata":{"id":"QyOxxAImSuFN"},"source":["class Dense_Block(nn.Module):\n","    def __init__(self, in_channels):\n","        super(Dense_Block, self).__init__()\n","\n","        # self.relu = nn.LeakyReLU(inplace=True)\n","        # self.relu = nn.ReLU(inplace = True)\n","        # self.activation = nn.ELU()\n","        self.activation = nn.ReLU()\n","        self.bn = nn.BatchNorm2d(num_features = in_channels)\n","\n","        self.conv1 = nn.Conv2d(in_channels = in_channels, out_channels = 16, kernel_size = 3, stride = 1, padding = 1)\n","        self.conv2 = nn.Conv2d(in_channels = 16, out_channels = 16, kernel_size = 3, stride = 1, padding = 1)\n","        self.conv3 = nn.Conv2d(in_channels = 32, out_channels = 16, kernel_size = 3, stride = 1, padding = 1)\n","        self.conv4 = nn.Conv2d(in_channels = 48, out_channels = 16, kernel_size = 3, stride = 1, padding = 1)\n","        self.conv5 = nn.Conv2d(in_channels = 64, out_channels = 16, kernel_size = 3, stride = 1, padding = 1)\n","        # self.conv6 = nn.Conv2d(in_channels = 80, out_channels = 16, kernel_size = 3, stride = 1, padding = 1)\n","\n","    \n","    def forward(self, x):\n","\n","        bn = self.bn(x)\n","        conv1 = self.activation(self.conv1(bn))\n","\n","        conv2 = self.activation(self.conv2(conv1))\n","        c2_dense = self.activation(torch.cat([conv1, conv2], 1))\n","\n","        conv3 = self.activation(self.conv3(c2_dense))\n","        c3_dense = self.activation(torch.cat([conv1, conv2, conv3], 1))\n","\n","        conv4 = self.activation(self.conv4(c3_dense))\n","        c4_dense = self.activation(torch.cat([conv1, conv2, conv3, conv4], 1))\n","\n","        conv5 = self.activation(self.conv5(c4_dense))\n","        c5_dense = self.activation(torch.cat([conv1, conv2, conv3, conv4, conv5], 1))\n","\n","        return c5_dense\n","\n","\n","class Transition_Layer(nn.Module):\n","    def __init__(self, in_channels, out_channels):\n","        super(Transition_Layer, self).__init__()\n","\n","        self.activation = nn.ReLU()\n","        self.bn = nn.BatchNorm2d(num_features = out_channels)\n","        self.conv = nn.Conv2d(in_channels = in_channels, out_channels = out_channels, kernel_size = 1, bias = False)\n","        self.avg_pool = nn.AvgPool2d(kernel_size = 2, stride = 2, padding = 0)\n","\n","    def forward(self, x):\n","\n","        bn = self.bn(self.activation(self.conv(x)))\n","        out = self.avg_pool(bn)\n","\n","        return out\n","\n","class DenseNet(nn.Module):\n","    def __init__(self, nr_classes):\n","        super(DenseNet, self).__init__()\n","\n","        self.lowconv = nn.Conv2d(in_channels = 3, out_channels = 64, kernel_size = 7, padding = 3, bias = False)\n","        self.activation = nn.ReLU()\n","\n","        # Make Dense Blocks\n","        self.denseblock1 = self._make_dense_block(Dense_Block, 64)\n","        self.denseblock2 = self._make_dense_block(Dense_Block, 80)\n","        self.denseblock3 = self._make_dense_block(Dense_Block, 80)\n","\n","        # Make transition Layers\n","        self.transitionLayer1 = self._make_transition_layer(Transition_Layer, in_channels = 80, out_channels = 80)\n","        self.transitionLayer2 = self._make_transition_layer(Transition_Layer, in_channels = 80, out_channels = 80)\n","        self.transitionLayer3 = self._make_transition_layer(Transition_Layer, in_channels = 80, out_channels = 64)\n","\n","        # Classifier\n","        self.bn = nn.BatchNorm2d(num_features = 64)\n","        self.pre_classifier = nn.Linear(64*12*12, 192)\n","        self.classifier = nn.Linear(192, nr_classes)\n","\n","    def _make_dense_block(self, block, in_channels):\n","        layers = []\n","        layers.append(block(in_channels))\n","        return nn.Sequential(*layers)\n","\n","    def _make_transition_layer(self, layer, in_channels, out_channels):\n","        modules = []\n","        modules.append(layer(in_channels, out_channels))\n","        return nn.Sequential(*modules)\n","\n","    def forward(self, x):\n","        out = self.activation(self.lowconv(x))\n","        # print('self.relu(self.lowconv(x)): ', out.size())\n","\n","        out = self.denseblock1(out)\n","        # print('self.denseblock1(out): ', out.size())\n","        out = self.transitionLayer1(out)\n","        # print('self.transitionLayer1(out): ', out.size())\n","\n","        out = self.denseblock2(out)\n","        # print('self.denseblock2(out): ', out.size())\n","        out = self.transitionLayer2(out)\n","        # print('self.transitionLayer2(out): ', out.size())\n","\n","        out = self.denseblock3(out)\n","        # print('self.denseblock3(out): ', out.size())\n","        out = self.transitionLayer3(out)\n","        # print('self.transitionLayer3(out): ', out.size())\n","\n","        out = self.bn(out)\n","        # print('self.bn(out): ', out.size())\n","        # out = out.view(-1, 64*4*4)\n","        out = out.view(-1, 64*12*12)\n","        # print('out.view(-1, 64*12*12): ', out.size())\n","\n","        out = self.pre_classifier(out)\n","        # print('self.pre_classifier(out): ', out.size())\n","        out = self.classifier(out)\n","        # print('self.classifier(out): ', out.size())\n","\n","        return out"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"u78UL6OmjxkY"},"source":["## ResNet\n","https://github.com/kuangliu/pytorch-cifar/blob/master/models/resnet.py"]},{"cell_type":"markdown","metadata":{"id":"DNVzY7WUuh2u"},"source":["### v1"]},{"cell_type":"code","metadata":{"id":"eqeNsanXXTCN"},"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","class BasicBlock(nn.Module):\n","    expansion = 1\n","\n","    def __init__(self, in_planes, planes, stride=1):\n","        super(BasicBlock, self).__init__()\n","\n","        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(planes)\n","        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n","        self.bn2 = nn.BatchNorm2d(planes)\n","\n","        self.shortcut = nn.Sequential()\n","        if stride != 1 or in_planes != self.expansion*planes:\n","            self.shortcut = nn.Sequential(\n","                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n","                nn.BatchNorm2d(self.expansion*planes)\n","            )\n","\n","        # self.activation = nn.ReLU()\n","        self.activation = nn.ELU()\n","\n","    def forward(self, x):\n","        out = self.activation(self.bn1(self.conv1(x)))\n","        out = self.bn2(self.conv2(out))\n","        out += self.shortcut(x)\n","        out = self.activation(out)\n","        return out\n","\n","class ResNet(nn.Module):\n","    def __init__(self, block, num_blocks, num_classes=10):\n","        super(ResNet, self).__init__()\n","        self.in_planes = 64\n","\n","        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(64)\n","        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n","        self.layer2 = self._make_layer(block, 96, num_blocks[1], stride=2)\n","        self.layer3 = self._make_layer(block, 128, num_blocks[2], stride=2)\n","        self.layer4 = self._make_layer(block, 160, num_blocks[3], stride=2)\n","        self.linear = nn.Linear(640*block.expansion, num_classes)\n","\n","        # self.activation = nn.ReLU()\n","        self.activation = nn.ELU()\n","        \n","    def _make_layer(self, block, planes, num_blocks, stride):\n","        strides = [stride] + [1]*(num_blocks-1)\n","        layers = []\n","        for stride in strides:\n","            layers.append(block(self.in_planes, planes, stride))\n","            self.in_planes = planes * block.expansion\n","        return nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","\n","        out = self.activation(self.bn1(self.conv1(x)))\n","        out = self.layer1(out)\n","        out = self.layer2(out)\n","        out = self.layer3(out)\n","        out = self.layer4(out)\n","        out = F.avg_pool2d(out, 4)\n","        out = out.view(out.size(0), -1)\n","        out = self.linear(out)\n","        return out\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sYv9jHwj6xYE"},"source":["### v2\n"]},{"cell_type":"code","metadata":{"id":"g0bW4KX06zIt"},"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","class BasicBlock(nn.Module):\n","    expansion = 1\n","\n","    def __init__(self, in_planes, planes, stride=1):\n","        super(BasicBlock, self).__init__()\n","\n","        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(planes)\n","        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n","        self.bn2 = nn.BatchNorm2d(planes)\n","\n","        self.shortcut = nn.Sequential()\n","        if stride != 1 or in_planes != self.expansion*planes:\n","            self.shortcut = nn.Sequential(\n","                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n","                nn.BatchNorm2d(self.expansion*planes)\n","            )\n","\n","        # self.activation = nn.ReLU()\n","        self.activation = nn.ELU()\n","\n","    def forward(self, x):\n","        out = self.activation(self.bn1(self.conv1(x)))\n","        out = self.bn2(self.conv2(out))\n","        out += self.shortcut(x)\n","        out = self.activation(out)\n","        return out\n","\n","class ResNet(nn.Module):\n","    def __init__(self, block, num_blocks, num_classes=10):\n","        super(ResNet, self).__init__()\n","        self.in_planes = 64\n","\n","        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(64)\n","        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n","        self.layer2 = self._make_layer(block, 96, num_blocks[1], stride=2)\n","        self.layer3 = self._make_layer(block, 128, num_blocks[2], stride=2)\n","        self.layer4 = self._make_layer(block, 160, num_blocks[3], stride=2)\n","\n","        self.linear1 = nn.Linear(640*block.expansion, 64)\n","        self.classifier = nn.Linear(64, num_classes)\n","\n","        # self.activation = nn.ReLU()\n","        self.activation = nn.ELU()\n","        \n","    def _make_layer(self, block, planes, num_blocks, stride):\n","        strides = [stride] + [1]*(num_blocks-1)\n","        layers = []\n","        for stride in strides:\n","            layers.append(block(self.in_planes, planes, stride))\n","            self.in_planes = planes * block.expansion\n","        return nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","\n","        out = self.activation(self.bn1(self.conv1(x)))\n","        out = self.layer1(out)\n","        out = self.layer2(out)\n","        out = self.layer3(out)\n","        out = self.layer4(out)\n","        out = F.avg_pool2d(out, 4)\n","        out = out.view(out.size(0), -1)\n","\n","        out = self.activation(self.linear1(out))\n","        out = self.classifier(out)\n","        \n","        return out\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SDupYtbjjmZD"},"source":["### v3"]},{"cell_type":"code","metadata":{"id":"r4IETSiajpmn"},"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","class BasicBlock(nn.Module):\n","    expansion = 1\n","\n","    def __init__(self, in_planes, planes, stride=1):\n","        super(BasicBlock, self).__init__()\n","\n","        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(planes)\n","        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n","        self.bn2 = nn.BatchNorm2d(planes)\n","\n","        self.shortcut = nn.Sequential()\n","        if stride != 1 or in_planes != self.expansion*planes:\n","            self.shortcut = nn.Sequential(\n","                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n","                nn.BatchNorm2d(self.expansion*planes)\n","            )\n","\n","        # self.activation = nn.ReLU()\n","        self.activation = nn.ELU()\n","\n","    def forward(self, x):\n","        out = self.activation(self.bn1(self.conv1(x)))\n","        out = self.bn2(self.conv2(out))\n","        out += self.shortcut(x)\n","        out = self.activation(out)\n","        return out\n","\n","class ResNet(nn.Module):\n","    def __init__(self, block, num_blocks, num_classes=10):\n","        super(ResNet, self).__init__()\n","        self.in_planes = 64\n","\n","        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(64)\n","        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n","        self.layer2 = self._make_layer(block, 96, num_blocks[1], stride=2)\n","        self.layer3 = self._make_layer(block, 112, num_blocks[2], stride=2)\n","        self.layer4 = self._make_layer(block, 160, num_blocks[3], stride=2)\n","\n","        self.linear1 = nn.Linear(1440*block.expansion, 128)\n","        self.classifier = nn.Linear(128, num_classes)\n","\n","        # self.activation = nn.ReLU()\n","        self.activation = nn.ELU()\n","        \n","    def _make_layer(self, block, planes, num_blocks, stride):\n","        strides = [stride] + [1]*(num_blocks-1)\n","        layers = []\n","        for stride in strides:\n","            layers.append(block(self.in_planes, planes, stride))\n","            self.in_planes = planes * block.expansion\n","        return nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","\n","        out = self.activation(self.bn1(self.conv1(x)))\n","        out = self.layer1(out)\n","        out = self.layer2(out)\n","        out = self.layer3(out)\n","        out = self.layer4(out)\n","        out = F.avg_pool2d(out, 4)\n","        out = out.view(out.size(0), -1)\n","\n","        out = self.activation(self.linear1(out))\n","        out = self.classifier(out)\n","        \n","        return out\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"duruCS129-1x"},"source":["### v4"]},{"cell_type":"code","metadata":{"id":"o9vioTvl-AdU"},"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","class BasicBlock(nn.Module):\n","    expansion = 1\n","\n","    def __init__(self, in_planes, planes, stride=1):\n","        super(BasicBlock, self).__init__()\n","\n","        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(planes)\n","        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n","        self.bn2 = nn.BatchNorm2d(planes)\n","\n","        self.shortcut = nn.Sequential()\n","        if stride != 1 or in_planes != self.expansion*planes:\n","            self.shortcut = nn.Sequential(\n","                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n","                nn.BatchNorm2d(self.expansion*planes)\n","            )\n","\n","        self.activation = nn.ReLU()\n","        # self.activation = nn.ELU()\n","\n","    def forward(self, x):\n","        out = self.activation(self.bn1(self.conv1(x)))\n","        out = self.bn2(self.conv2(out))\n","        out += self.shortcut(x)\n","        out = self.activation(out)\n","        return out\n","\n","class ResNet(nn.Module):\n","    def __init__(self, block, num_blocks, num_classes=10):\n","        super(ResNet, self).__init__()\n","        self.in_planes = 64\n","\n","        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(64)\n","        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n","        self.layer2 = self._make_layer(block, 96, num_blocks[1], stride=2)\n","        self.layer3 = self._make_layer(block, 128, num_blocks[2], stride=2)\n","        self.layer4 = self._make_layer(block, 160, num_blocks[3], stride=2)\n","\n","        self.classifier = nn.Linear(1440*block.expansion, num_classes)\n","\n","        self.activation = nn.ReLU()\n","        # self.activation = nn.ELU()\n","        \n","    def _make_layer(self, block, planes, num_blocks, stride):\n","        strides = [stride] + [1]*(num_blocks-1)\n","        layers = []\n","        for stride in strides:\n","            layers.append(block(self.in_planes, planes, stride))\n","            self.in_planes = planes * block.expansion\n","        return nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","\n","        out = self.activation(self.bn1(self.conv1(x)))\n","        out = self.layer1(out)\n","        out = self.layer2(out)\n","        out = self.layer3(out)\n","        out = self.layer4(out)\n","        out = F.avg_pool2d(out, 4)\n","        out = out.view(out.size(0), -1)\n","\n","        out = self.classifier(out)\n","        \n","        return out\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gLj1Zg3iIQQi"},"source":["### v5"]},{"cell_type":"code","metadata":{"id":"cz1tRpZjIPwc"},"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","class BasicBlock(nn.Module):\n","    expansion = 1\n","\n","    def __init__(self, in_planes, planes, stride=1):\n","        super(BasicBlock, self).__init__()\n","\n","        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(planes)\n","        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n","        self.bn2 = nn.BatchNorm2d(planes)\n","\n","        self.shortcut = nn.Sequential()\n","        if stride != 1 or in_planes != self.expansion*planes:\n","            self.shortcut = nn.Sequential(\n","                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n","                nn.BatchNorm2d(self.expansion*planes)\n","            )\n","\n","        # self.activation = nn.ReLU()\n","        self.activation = nn.ELU()\n","\n","    def forward(self, x):\n","        out = self.activation(self.bn1(self.conv1(x)))\n","        out = self.bn2(self.conv2(out))\n","        out += self.shortcut(x)\n","        out = self.activation(out)\n","        return out\n","\n","class ResNet(nn.Module):\n","    def __init__(self, block, num_blocks, num_classes=10):\n","        super(ResNet, self).__init__()\n","        self.in_planes = 64\n","\n","        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(64)\n","        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n","        self.layer2 = self._make_layer(block, 96, num_blocks[1], stride=2)\n","        self.layer3 = self._make_layer(block, 124, num_blocks[2], stride=2)\n","        self.layer4 = self._make_layer(block, 160, num_blocks[3], stride=2)\n","\n","        self.linear1 = nn.Linear(1440*block.expansion, 64)\n","        self.classifier = nn.Linear(64, num_classes)\n","\n","        # self.activation = nn.ReLU()\n","        self.activation = nn.ELU()\n","        \n","    def _make_layer(self, block, planes, num_blocks, stride):\n","        strides = [stride] + [1]*(num_blocks-1)\n","        layers = []\n","        for stride in strides:\n","            layers.append(block(self.in_planes, planes, stride))\n","            self.in_planes = planes * block.expansion\n","        return nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","\n","        out = self.activation(self.bn1(self.conv1(x)))\n","        out = self.layer1(out)\n","        out = self.layer2(out)\n","        out = self.layer3(out)\n","        out = self.layer4(out)\n","        out = F.avg_pool2d(out, 4)\n","\n","        # out = out.view(out.size(0), -1)\n","        out = out.reshape(out.size(0), out.size(1)*out.size(2)*out.size(3))\n","        \n","        out = self.activation(self.linear1(out))\n","        out = self.classifier(out)\n","        \n","        return out\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Zhot0C3rQnaJ"},"source":["### v6"]},{"cell_type":"code","metadata":{"id":"CkWXix_-Qp6m"},"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","class BasicBlock(nn.Module):\n","    expansion = 1\n","\n","    def __init__(self, in_planes, planes, stride=1):\n","        super(BasicBlock, self).__init__()\n","\n","        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(planes)\n","        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n","        self.bn2 = nn.BatchNorm2d(planes)\n","\n","        self.shortcut = nn.Sequential()\n","        if stride != 1 or in_planes != self.expansion*planes:\n","            self.shortcut = nn.Sequential(\n","                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n","                nn.BatchNorm2d(self.expansion*planes)\n","            )\n","\n","        # self.activation = nn.ReLU()\n","        self.activation = nn.ELU()\n","\n","    def forward(self, x):\n","        out = self.activation(self.bn1(self.conv1(x)))\n","        out = self.bn2(self.conv2(out))\n","        out += self.shortcut(x)\n","        out = self.activation(out)\n","        return out\n","\n","class ResNet(nn.Module):\n","    def __init__(self, block, num_blocks, num_classes=10):\n","        super(ResNet, self).__init__()\n","        self.in_planes = 64\n","\n","        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(64)\n","        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n","        self.layer2 = self._make_layer(block, 96, num_blocks[1], stride=2)\n","        self.layer3 = self._make_layer(block, 126, num_blocks[2], stride=2)\n","        self.layer4 = self._make_layer(block, 160, num_blocks[3], stride=2)\n","\n","        self.linear1 = nn.Linear(1440*block.expansion, 64)\n","        self.classifier = nn.Linear(64, num_classes)\n","\n","        # self.activation = nn.ReLU()\n","        self.activation = nn.ELU()\n","        \n","    def _make_layer(self, block, planes, num_blocks, stride):\n","        strides = [stride] + [1]*(num_blocks-1)\n","        layers = []\n","        for stride in strides:\n","            layers.append(block(self.in_planes, planes, stride))\n","            self.in_planes = planes * block.expansion\n","        return nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","\n","        out = self.activation(self.bn1(self.conv1(x)))\n","        out = self.layer1(out)\n","        out = self.layer2(out)\n","        out = self.layer3(out)\n","        out = self.layer4(out)\n","        out = F.avg_pool2d(out, 4)\n","\n","        # out = out.view(out.size(0), -1)\n","        out = out.reshape(out.size(0), out.size(1)*out.size(2)*out.size(3))\n","        \n","        out = self.activation(self.linear1(out))\n","        out = self.classifier(out)\n","        \n","        return out\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gWmoyVvhs9YR"},"source":["# Utils"]},{"cell_type":"code","metadata":{"id":"bujKC629SDzx"},"source":["# Get your model here. \n","# This function returns the actual model and its name. \n","# The name just for logging purpose and not important. \n","# You can return an empty string as the name.\n","\n","def Model():\n","    # return LeNet_STL10(), 'LeNet_STL10'\n","    # return DenseNet(10), 'DenseNet'\n","    return ResNet(BasicBlock, [2, 2, 2, 2]), 'ResNet18'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SM2wtvcUCEV_"},"source":["# This is also to keep track of the different changes. You can just put an empty string.\n","\n","# note = 'DenseNet. Convolutional output is 16 channels. Removed contrast=(0.5, 2), saturation=(0.5, 2), hue=(-0.1, 0.1)'\n","# note = 'Lenet with relu. optimizer changed to adam. increased patience to 25. learning rate decreased.'\n","note = 'ResNet18.v3. Random affine, perspective, and erasing are included. Patience increased to 50.'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"j23TQSJi42F_"},"source":["# Check number of parameters of your mode.\n","model, model_architecture = Model()\n","pytorch_total_params = sum(p.numel() for p in model.parameters())\n","\n","print(f\"Number of parameters: {pytorch_total_params}\")\n","\n","print(int(pytorch_total_params))\n","print(2000000)\n","\n","assert int(pytorch_total_params) <= 2000000, 'Your model has the number of parameters more than 2 millions..'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6tpJEJ2WtEgS"},"source":["class AverageMeter(object):\n","    r\"\"\"Computes and stores the average and current value\n","    \"\"\"\n","    def __init__(self, name, fmt=':f'):\n","        self.name = name\n","        self.fmt = fmt\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        \n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count\n","\n","    def __str__(self):\n","        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n","        return fmtstr.format(**self.__dict__)\n","\n","\n","class ProgressMeter(object):\n","    def __init__(self, num_batches, *meters, prefix=\"\"):\n","        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n","        self.meters = meters\n","        self.prefix = prefix\n","\n","    def print(self, batch):\n","        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n","        entries += [str(meter) for meter in self.meters]\n","        print('\\t'.join(entries))\n","\n","    def _get_batch_fmtstr(self, num_batches):\n","        num_digits = len(str(num_batches // 1))\n","        fmt = '{:' + str(num_digits) + 'd}'\n","        return '[' + fmt + '/' + fmt.format(num_batches) + ']'\n","\n","\n","def accuracy(output, target, topk=(1,)):\n","    r\"\"\"Computes the accuracy over the $k$ top predictions for the specified values of k\n","    \"\"\"\n","    with torch.no_grad():\n","        maxk = max(topk)\n","        batch_size = target.size(0)\n","\n","        # _, pred = output.topk(maxk, 1, True, True)\n","        # pred = pred.t()\n","        # correct = pred.eq(target.view(1, -1).expand_as(pred))\n","\n","        # faster topk (ref: https://github.com/pytorch/pytorch/issues/22812)\n","        _, idx = output.sort(descending=True)\n","        pred = idx[:,:maxk]\n","        pred = pred.t()\n","        correct = pred.eq(target.view(1, -1).expand_as(pred))\n","\n","        res = []\n","        for k in topk:\n","            # correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n","            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n","            res.append(correct_k.mul_(100.0 / batch_size))\n","        return res"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pdoV2ndBtHMR"},"source":["## Hyperparameters"]},{"cell_type":"code","metadata":{"id":"9zowgJx8tIE5"},"source":["current_time = datetime.now().strftime(\"%Y%m%d%H%M%S\") \n","SAVEPATH = os.path.join(ROOT_DIR, 'checkpoints', current_time)  # Path to save the models, logs, note.\n","LOG_DIR = os.path.join(SAVEPATH, 'logs')\n","os.makedirs(SAVEPATH, exist_ok=True)\n","\n","PRINTFREQ = 10\n","\n","WEIGHTDECAY = 5e-4\n","MOMENTUM = 0.9\n","BATCHSIZE = 64\n","EPOCHS = 5000\n","ES_PATIENCE = 30    # Early stopping patience."],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jHORtcINuMVa"},"source":["## Train Model"]},{"cell_type":"code","metadata":{"id":"a6nt9br2uGEM"},"source":["import time\n","\n","import torch\n","import torch.nn as nn\n","\n","import torchvision\n","import torchvision.transforms as transforms\n","from torch.utils.data import Dataset, DataLoader\n","from torch.utils.tensorboard import SummaryWriter"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Kcxox48reXJp"},"source":["def train(train_loader, epoch, model, optimizer, criterion):\n","    batch_time = AverageMeter('Time', ':6.3f')\n","    data_time = AverageMeter('Data', ':6.3f')\n","    losses = AverageMeter('Loss', ':.4e')\n","    top1 = AverageMeter('Acc@1', ':6.2f')\n","    top5 = AverageMeter('Acc@5', ':6.2f')\n","    progress = ProgressMeter(len(train_loader), batch_time, data_time, losses,\n","                             top1, top5, prefix=\"Epoch: [{}]\".format(epoch))\n","    # switch to train mode\n","    model.train()\n","\n","    end = time.time()\n","    for i, (input, target) in enumerate(train_loader):\n","        # measure data loading time\n","        data_time.update(time.time() - end)\n","\n","        input = input.cuda()\n","        target = target.cuda()\n","\n","        # compute output\n","        output = model(input)\n","        loss = criterion(output, target)\n","\n","        # measure accuracy and record loss, accuracy \n","        acc1, acc5 = accuracy(output, target, topk=(1, 5))\n","        losses.update(loss.item(), input.size(0))\n","        top1.update(acc1[0].item(), input.size(0))\n","        top5.update(acc5[0].item(), input.size(0))\n","\n","        # compute gradient and do SGD step\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        # measure elapsed time\n","        batch_time.update(time.time() - end)\n","        end = time.time()\n","\n","        if i % PRINTFREQ == 0:\n","            progress.print(i)\n","\n","    print('Training => Acc@1 {top1.avg:.3f} Acc@5 {top5.avg:.3f}'.format(top1=top1, top5=top5))\n","    return top1.avg, top5.avg, losses.avg\n","\n","# To validate the model on validation data.\n","def validate(validation_loader, model, criterion):\n","    val_losses = AverageMeter('Loss', ':.4e')\n","    val_top1 = AverageMeter('Acc@1', ':6.2f')\n","    val_top5 = AverageMeter('Acc@5', ':6.2f')\n","\n","    model.eval()\n","\n","    for i, (input, target) in enumerate(validation_loader):\n","        \n","        input = input.cuda()\n","        target = target.cuda()\n","\n","        # compute output\n","        output = model(input)\n","        loss = criterion(output, target)\n","\n","        # measure accuracy and record loss, accuracy \n","        acc1, acc5 = accuracy(output, target, topk=(1, 5))\n","        val_losses.update(loss.item(), input.size(0))\n","        val_top1.update(acc1[0].item(), input.size(0))\n","        val_top5.update(acc5[0].item(), input.size(0))\n","\n","    print('Validation => Acc@1 {top1.avg:.3f} Acc@5 {top5.avg:.3f}'.format(top1=val_top1, top5=val_top5))\n","    print('           => Loss {val_losses.avg:.4f}'.format(val_losses=val_losses))\n","    return val_top1.avg, val_top5.avg, val_losses.avg"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Nc9IqSdUg11O"},"source":["# Load tensorboard\n","%load_ext tensorboard\n","%tensorboard --logdir '{LOG_DIR}'\n","\n","# After a few minutes into the training, reload the below tensorboard to see your progress."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"H0XNoi3_7vMW"},"source":["model, model_architecture = Model()\n","\n","LR = 1e-4\n","# optimizer = torch.optim.SGD(model.parameters(), \n","#                             lr=LR,\n","#                             momentum=MOMENTUM, \n","#                             weight_decay=WEIGHTDECAY,\n","#                             nesterov=True)\n","\n","scheduler = None\n","# scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, [100, 150], gamma=0.1)\n","optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n","\n","criterion = torch.nn.CrossEntropyLoss()\n","\n","model = model.cuda()\n","criterion = criterion.cuda()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uGLgr75Bua_C"},"source":["normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","\n","# Augmentations for training.\n","train_transform = transforms.Compose([\n","    transforms.RandomCrop(96, padding=4),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.ColorJitter(brightness=(0.5, 2), contrast=(0.5, 2), saturation=(0.5, 2), hue=(-0.1, 0.1)),\n","    transforms.ToTensor(),\n","    transforms.RandomErasing(p=0.5, scale=(0.1, 0.1), ratio=(1, 1)),\n","    transforms.RandomAffine(degrees=10, translate=(0.05, 0.05), shear=5),\n","    transforms.RandomPerspective(distortion_scale=0.2),\n","    normalize\n","])\n","\n","\n","# Training data.\n","train_dataset = torchvision.datasets.ImageFolder(train_dir, transform=train_transform)\n","train_loader = DataLoader(train_dataset,\n","                            batch_size=BATCHSIZE, shuffle=True,\n","                            num_workers=0, pin_memory=True)\n","\n","\n","valid_transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    normalize\n","])\n","\n","# Validation data.\n","valid_dataset = torchvision.datasets.ImageFolder(valid_dir, transform=valid_transform)\n","valid_loader = DataLoader(valid_dataset,\n","                            batch_size=BATCHSIZE, shuffle=True,\n","                            num_workers=0, pin_memory=True)\n","\n","\n","# Variables for logging.\n","writer = SummaryWriter(LOG_DIR)\n","\n","top1_acc_train = None\n","top5_acc_train = None\n","loss_train = None\n","\n","top1_acc_valid = None\n","top5_acc_valid = None\n","loss_valid = None\n","\n","# For early stopping.\n","es_counter = 0\n","current_best_loss = np.Inf\n","current_best_acc = 0\n","model_name = ''\n","\n","last_epoch = 0\n","for epoch in range(EPOCHS):\n","\n","    print(\"\\n----- epoch: {}, lr: {} -----\".format(\n","        epoch, optimizer.param_groups[0][\"lr\"]))\n","\n","    start_time = time.time()\n","\n","    # Train\n","    top1_acc_train, top5_acc_train, loss_train = train(train_loader, epoch, model, optimizer, criterion)\n","    \n","    # Validate\n","    top1_acc_valid, top5_acc_valid, loss_valid = validate(valid_loader, model, criterion)\n","\n","    # Save history.\n","    writer.add_scalars('accuracy/top1', {\n","        'train':top1_acc_train,\n","        'valid':top1_acc_valid,\n","    }, epoch)\n","    \n","    writer.add_scalars('accuracy/top5', {\n","        'train':top5_acc_train,\n","        'valid':top5_acc_valid,\n","    }, epoch)\n","\n","    writer.add_scalars('loss', {\n","        'train':loss_train,\n","        'valid':loss_valid,\n","    }, epoch)\n","\n","    elapsed_time = time.time() - start_time\n","    print('==> {:.2f} seconds to train this epoch\\n'.format(elapsed_time))\n","\n","    # learning rate scheduling\n","    # scheduler.step()\n","\n","    # Save best model and early stopping.\n","    if loss_valid < current_best_loss:\n","        model_name = 'val_acc_{:.4f}_val_loss_{:.4f}_epoch_{}.pth'.format(top1_acc_valid, loss_valid, epoch)\n","        torch.save(model.state_dict(), os.path.join(SAVEPATH, model_name))\n","        current_best_loss = loss_valid\n","        current_best_acc = top1_acc_valid\n","        es_counter = 0\n","        last_epoch = epoch\n","    else:\n","        # if epoch > 30:\n","        es_counter += 1 \n","\n","    if es_counter >= ES_PATIENCE:\n","        print('Early stopped at epoch: {}'.format(epoch))\n","        break\n","\n","print(f\"Train Top-1 Accuracy: {top1_acc_train}\")\n","print(f\"Valid Top-1 Accuracy: {top1_acc_valid}\")\n","\n","print(f\"Best Accuracy: {current_best_acc}\")\n","print(f\"Best Loss: {current_best_loss}\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vYUYBPeYOq6d"},"source":["# Delete other models except the best one.\n","for item in os.listdir(SAVEPATH):\n","    if item != 'logs' and item != model_name:\n","        os.remove(os.path.join(SAVEPATH, item))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rz7d5P--BOFl"},"source":["model, _ = Model()\n","model = model.cuda()\n","model.load_state_dict(torch.load(os.path.join(SAVEPATH, model_name)))\n","top1_acc_valid, top5_acc_valid, loss_valid = validate(valid_loader, model, criterion)\n","\n","print(f\"Valid Top-1 Accuracy: {top1_acc_valid}\")\n","print(f\"Best Loss: {loss_valid}\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FGVIHR2QESMl"},"source":["# Save some information to keep track of the models.\n","def save_model_info():\n","    info_file = os.path.join(SAVEPATH, 'info.txt')\n","    info = '''\n","    MODEL : {}\n","    BATCHSIZE : {}\\n\n","    EPOCHS : {}\\n \n","    ES_PATIENCE : {}\\n\n","\n","    optimizer : {}\\n\n","    scheduler : {}\\n\n","    criterion : {}\\n\n","    train_transform : {}\\n\\n\n","\n","    best_valid_acc : {}\\n\n","    train_acc_top1 : {}\\n\n","    valid_acc_top1 : {}\\n\n","\n","    pytorch_total_params : {}\\n\\n\n","    \n","    note : {}\\n\n","    '''.format(model_architecture, BATCHSIZE, last_epoch, ES_PATIENCE, optimizer, scheduler, criterion, train_transform, current_best_acc, top1_acc_train, top1_acc_valid, pytorch_total_params, note)\n","    \n","    with open(info_file, 'w') as f:\n","        f.write(info)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6AKnSASFegW_"},"source":["save_model_info()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ACnCiaTIvOYq"},"source":["## Make an evalutation csv file"]},{"cell_type":"code","metadata":{"id":"HUb183WwvNia"},"source":["import torch\n","import pandas as pd\n","import argparse\n","import time\n","import torchvision\n","import torchvision.transforms as transforms\n","from torch.utils.data import Dataset, DataLoader"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9V6F6srSw6Vx"},"source":["def eval():\n","    ########## You can change this part only in this cell ##########\n","    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n","                                     std=[0.229, 0.224, 0.225])\n","    test_transform = transforms.Compose([\n","        transforms.ToTensor(),\n","        normalize\n","    ])\n","    ################################################################\n","\n","    test_dataset = torchvision.datasets.ImageFolder(test_dir, transform=test_transform)\n","    test_loader = DataLoader(test_dataset, batch_size=BATCHSIZE, num_workers=0, shuffle=False)\n","\n","    model, _ = Model()\n","    model = model.cuda()\n","    model.load_state_dict(torch.load(os.path.join(SAVEPATH, model_name)))\n","\n","    print('Make an evaluation csv file for kaggle submission...')\n","    Category = []\n","    for input, _ in test_loader:\n","        input = input.cuda()\n","        output = model(input)\n","        output = torch.argmax(output, dim=1)\n","        Category = Category + output.tolist()\n","\n","    Id = list(range(0, 8000))\n","    samples = {\n","       'Id': Id,\n","       'Category': Category \n","    }\n","    df = pd.DataFrame(samples, columns=['Id', 'Category'])\n","\n","    df.to_csv(os.path.join(SAVEPATH, 'submission.csv'), index=False)\n","    print('Done!!')\n","\n","\n","if __name__ == \"__main__\":\n","    eval()"],"execution_count":null,"outputs":[]}]}